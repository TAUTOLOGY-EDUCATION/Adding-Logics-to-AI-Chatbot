{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "BGKzwUR8YziM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGKzwUR8YziM",
        "outputId": "71bc5b4f-c655-4ed0-b3f1-5a3e068c9936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.42.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Downloading openai-1.42.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.9/362.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 openai-1.42.0\n"
          ]
        }
      ],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ef9de964-9dca-441c-8a0c-f3789c890062",
      "metadata": {
        "id": "ef9de964-9dca-441c-8a0c-f3789c890062"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f1a114af",
      "metadata": {
        "id": "f1a114af"
      },
      "outputs": [],
      "source": [
        "# Generate API KEY from OPENAI website and define as a variable.\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "40385371",
      "metadata": {
        "id": "40385371"
      },
      "outputs": [],
      "source": [
        "# Create the language model\n",
        "llm1 = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ab115476",
      "metadata": {
        "id": "ab115476"
      },
      "outputs": [],
      "source": [
        "def domestic_market_competition(query, llm):\n",
        "\n",
        "    full_query = f\"\\nUser: {query}\"\n",
        "\n",
        "    system_content = \"\"\"Based on the user's input, respond from the perspective of 'Domestic Market Competition.'\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": f\"{system_content}\"},\n",
        "        {\"role\": \"user\", \"content\": full_query}\n",
        "    ]\n",
        "\n",
        "    chain1 = llm.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    result = chain1.choices[0].message.content\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "tH7tsc7VQlta",
      "metadata": {
        "id": "tH7tsc7VQlta"
      },
      "outputs": [],
      "source": [
        "def price_undercutting(query, llm):\n",
        "\n",
        "    full_query = f\"\\nUser: {query}\"\n",
        "\n",
        "    system_content = \"\"\"Based on the user's input, respond from the perspective of 'Price Undercutting.'\n",
        "                        Effect on Thai producers and small businesses.\n",
        "                        Sectors most vulnerable to Chinese price competition.\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": f\"{system_content}\"},\n",
        "        {\"role\": \"user\", \"content\": full_query}\n",
        "    ]\n",
        "\n",
        "    chain1 = llm.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    result = chain1.choices[0].message.content\n",
        "    return result\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "P_Jun9ouSE06",
      "metadata": {
        "id": "P_Jun9ouSE06"
      },
      "outputs": [],
      "source": [
        "def market_share_losses(query, llm):\n",
        "\n",
        "    full_query = f\"\\nUser: {query}\"\n",
        "\n",
        "    system_content = \"\"\"Based on the user's input, respond from the perspective of 'Market Share Losses.'\n",
        "                        Displacement of local products by cheaper Chinese alternatives.\n",
        "                        Survival strategies for Thai businesses.\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": f\"{system_content}\"},\n",
        "        {\"role\": \"user\", \"content\": full_query}\n",
        "    ]\n",
        "\n",
        "    chain1 = llm.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    result = chain1.choices[0].message.content\n",
        "    return result\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "84EXyt-tSlTO",
      "metadata": {
        "id": "84EXyt-tSlTO"
      },
      "outputs": [],
      "source": [
        "def innovation_and_quality_improvement(query, llm):\n",
        "\n",
        "    full_query = f\"\\nUser: {query}\"\n",
        "\n",
        "    system_content = \"\"\"Based on the user's input, respond from the perspective of 'Innovation and Quality Improvement.'\n",
        "                        Need for innovation in Thai industries to compete on quality rather than price.\n",
        "                        Investments in technology and R&D by Thai companies.\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": f\"{system_content}\"},\n",
        "        {\"role\": \"user\", \"content\": full_query}\n",
        "    ]\n",
        "\n",
        "    chain1 = llm.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    result = chain1.choices[0].message.content\n",
        "    return result\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "SKZ-_Jf5UMuf",
      "metadata": {
        "id": "SKZ-_Jf5UMuf"
      },
      "outputs": [],
      "source": [
        "def consumer_behavior(query, llm):\n",
        "\n",
        "    full_query = f\"\\nUser: {query}\"\n",
        "\n",
        "    system_content = \"\"\"Based on the user's input, respond from the perspective of 'Consumer Behavior.'\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": f\"{system_content}\"},\n",
        "        {\"role\": \"user\", \"content\": full_query}\n",
        "    ]\n",
        "\n",
        "    chain1 = llm.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    result = chain1.choices[0].message.content\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0nhm501DUdy-",
      "metadata": {
        "id": "0nhm501DUdy-"
      },
      "outputs": [],
      "source": [
        "def demand_for_cheaper_goods(query, llm):\n",
        "\n",
        "    full_query = f\"\\nUser: {query}\"\n",
        "\n",
        "    system_content = \"\"\"Based on the user's input, respond from the perspective of 'Demand for Cheaper Goods.'\n",
        "                        Shift in consumer preferences toward lower-cost Chinese products.\n",
        "                        Impact on local brands and traditional products.\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": f\"{system_content}\"},\n",
        "        {\"role\": \"user\", \"content\": full_query}\n",
        "    ]\n",
        "\n",
        "    chain1 = llm.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    result = chain1.choices[0].message.content\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "dnV41pX0U4zZ",
      "metadata": {
        "id": "dnV41pX0U4zZ"
      },
      "outputs": [],
      "source": [
        "def disposable_income_and_spending_patterns(query, llm):\n",
        "\n",
        "    full_query = f\"\\nUser: {query}\"\n",
        "\n",
        "    system_content = \"\"\"Based on the user's input, respond from the perspective of 'Disposable Income and Spending Patterns.'\n",
        "                        Increase in consumer spending power due to lower prices.\n",
        "                        Changes in household consumption patterns.\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": f\"{system_content}\"},\n",
        "        {\"role\": \"user\", \"content\": full_query}\n",
        "    ]\n",
        "\n",
        "    chain1 = llm.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    result = chain1.choices[0].message.content\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "WdwghdDYVb7_",
      "metadata": {
        "id": "WdwghdDYVb7_"
      },
      "outputs": [],
      "source": [
        "def brand_layalty_and_perception(query, llm):\n",
        "\n",
        "    full_query = f\"\\nUser: {query}\"\n",
        "\n",
        "    system_content = \"\"\"Based on the user's input, respond from the perspective of 'Brand Loyalty and Perception.'\n",
        "                        Erosion of brand loyalty for Thai products.\n",
        "                        Perception of Chinese goods in the Thai market.\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": f\"{system_content}\"},\n",
        "        {\"role\": \"user\", \"content\": full_query}\n",
        "    ]\n",
        "\n",
        "    chain1 = llm.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    result = chain1.choices[0].message.content\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3uyEz34HWaTO",
      "metadata": {
        "id": "3uyEz34HWaTO"
      },
      "outputs": [],
      "source": [
        "def make_conclusion(query, llm):\n",
        "\n",
        "    full_query = f\"\\nUser: {query}\"\n",
        "\n",
        "    system_content = \"\"\"Based on the user's input, draw the best conclusion\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": f\"{system_content}\"},\n",
        "        {\"role\": \"user\", \"content\": full_query}\n",
        "    ]\n",
        "\n",
        "    chain1 = llm.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    result = chain1.choices[0].message.content\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "x5hrM4TUw2gd",
      "metadata": {
        "id": "x5hrM4TUw2gd"
      },
      "outputs": [],
      "source": [
        "def reflection(query, llm):\n",
        "\n",
        "    full_query = f\"\\nUser: {query}\"\n",
        "\n",
        "    system_content = \"\"\"Your role is reflection. Then, write new one with your reflection.\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": f\"{system_content}\"},\n",
        "        {\"role\": \"user\", \"content\": full_query}\n",
        "    ]\n",
        "\n",
        "    chain1 = llm.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    result = chain1.choices[0].message.content\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ee4cdea9",
      "metadata": {
        "id": "ee4cdea9"
      },
      "outputs": [],
      "source": [
        "query = \"What is the potential impact of Chinese price war on Thailand economy?\"\n",
        "\n",
        "response_domestic_market_competition = domestic_market_competition(query, llm1)\n",
        "# reflection\n",
        "reflection_response_domestic_market_competition = reflection(response_domestic_market_competition, llm1)\n",
        "response_price_undercutting = price_undercutting(reflection_response_domestic_market_competition, llm1)\n",
        "response_market_share_losses = market_share_losses(reflection_response_domestic_market_competition, llm1)\n",
        "response_response_domestic_market_competition = innovation_and_quality_improvement(reflection_response_domestic_market_competition, llm1)\n",
        "\n",
        "response_consumer_behavior = consumer_behavior(query, llm1)\n",
        "# reflection\n",
        "reflection_response_consumer_behavior = reflection(response_consumer_behavior, llm1)\n",
        "response_demand_for_cheaper_goods = demand_for_cheaper_goods(response_consumer_behavior, llm1)\n",
        "response_disposable_income_and_spending_patterns = disposable_income_and_spending_patterns(response_consumer_behavior, llm1)\n",
        "response_brand_layalty_and_perception = brand_layalty_and_perception(response_consumer_behavior, llm1)\n",
        "\n",
        "final_query = response_price_undercutting + \\\n",
        "              response_market_share_losses + \\\n",
        "              response_response_domestic_market_competition + \\\n",
        "              response_demand_for_cheaper_goods + \\\n",
        "              response_disposable_income_and_spending_patterns + \\\n",
        "              response_brand_layalty_and_perception\n",
        "\n",
        "final_response = make_conclusion(final_query, llm1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2ew8thFeXd1P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "2ew8thFeXd1P",
        "outputId": "33551b37-ab60-4625-ef46-b6803b820cb0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Based on the user's inputs, the best conclusion is that a Chinese price war in Thailand can have both positive and negative impacts. It can increase consumer purchasing power and provide more affordable options for consumers. However, it can also lead to market share losses and potentially lower profitability for domestic producers. Thai businesses will need to focus on differentiation, innovation, and quality improvement to remain competitive. Additionally, there may be a potential erosion of brand loyalty for Thai products and a shift in consumer perception of Chinese goods. Thai businesses will need to work on building trust and improving customer loyalty to mitigate these negative effects.\""
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "jVqVi2S4aI6s",
      "metadata": {
        "id": "jVqVi2S4aI6s"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
